# -*- coding: utf-8 -*-
"""FoodClassification_29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qghBKWOJZGsIrxKezpFQYXofhKfGAeUG

# Training and Visulization for the Food Images Dataset

### Necessary imports
"""

import os
import csv
import time
import glob
import copy
import random
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from pprint import pprint

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision import datasets, models, transforms


import albumentations as A
from albumentations.pytorch import ToTensorV2
import torch.backends.cudnn as cudnn

from config import RANDOM_SEED, NUM_CATEGORIES, NUM_EPOCHS, BATCH_SIZE, IMG_SIZE, DATASET_FOLDER, SAVING_CHECKPOINT, TRAIN_TEST_RATIO, TRAIN_CSV, VAL_CSV
from utils import visualize_augmentations, FoodDataset
#OSError: image file is truncated (1 bytes not processed)
# Got this error during a times loading the dataset(reading the image files) --> Solution
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True



dataset_folder = DATASET_FOLDER
img_categories = [f for f in os.listdir(dataset_folder) if not f.startswith('.')]
img_categories.sort() #sorted to keep order consistent

num_epochs = NUM_EPOCHS
num_categories = NUM_CATEGORIES

assert num_categories == len(img_categories), f"Number of Categories read and param not same, {len(img_categories), num_categories}"
pprint(f"Total Food Categories: {num_categories}" )
pprint(img_categories)


cls2idx= {cls: idx for idx, cls in enumerate(img_categories)}
idx2cls = {idx: cls for idx, cls in enumerate(img_categories)}

print("Class-Category Mapping:")
pprint(cls2idx, idx2cls)


nums = []
for category in img_categories:
  nums.append(len(os.listdir(os.path.join(dataset_folder, category))))

nums, sum(nums)

"""### Read all the image paths and prepare the dataset"""

image_paths = []
for file in glob.glob(f"{dataset_folder}/*/*"):
  image_paths.append(file)



"""# Different transformations for train-valdiation"""

train_transforms = A.Compose(
    [
        A.SmallestMaxSize(max_size=350),
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),
        # A.Resize(600, 600, always_apply=True),
        A.RandomCrop(height=IMG_SIZE[0], width=IMG_SIZE[1]),
        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),
        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),
        ToTensorV2(),
    ]
)

test_transforms = A.Compose(
    [
        A.SmallestMaxSize(max_size=350),
        A.CenterCrop(height=IMG_SIZE[0], width=IMG_SIZE[1]),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ]
)

"""### Prepare Train-Valid Split: Random(80%-20%) 
"""

random.seed(RANDOM_SEED) #earlier forgot about the seed! :-<
random.shuffle(image_paths)

train_size = int(len(image_paths)*TRAIN_TEST_RATIO)
val_size = len(image_paths) - train_size

train_paths = image_paths[:train_size]
val_paths = image_paths[train_size:]

with open(TRAIN_CSV, 'w') as myfile:
    wr = csv.writer(myfile, delimiter= "\n", quoting=csv.QUOTE_ALL)
    wr.writerow(train_paths)

with open(VAL_CSV, 'w') as myfile:
    wr = csv.writer(myfile, delimiter= "\n", quoting=csv.QUOTE_ALL)
    wr.writerow(val_paths)

assert train_size + val_size == len(image_paths), "Number of Images in folder and CSV not same"
assert len(train_paths)+len(val_paths) == len(image_paths), "Number of Images in folder and CSV not same"

"""### Dataset and Dataloader"""

train_dataset = FoodDataset(train_paths, transforms= train_transforms)
val_dataset = FoodDataset(val_paths, transforms = test_transforms)

# visualize_augmentations(val_dataset)

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
device

train_loader = DataLoader(
    train_dataset, batch_size=8, shuffle=True
)
val_loader = DataLoader(
    val_dataset, batch_size=8, snum_ftrs = model_ft.fc.in_features, shuffle=True
# Adding a extra layer with 11 number of classes 
)

# print(next(iter(train_loader))[1])
print("Dataloader checking batch size and img shape")
pprint(next(iter(val_loader))[0].shape, next(iter(val_loader))[1].shape)

"""Checking if the dataset and dataloader working as expected"""

datasetloaders = {'train': train_loader, 'val': val_loader}
dataset_sizes = {'train': train_size, 'val': val_size}

"""### Accessory Function for Training """

def train_model(dataloaders, dataset_sizes, model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:4f}')

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model






model_ft = models.resnet50(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, len(num_categories))
model_ft = model_ft.to(device)


criterion = nn.CrossEntropyLoss()
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)


model_ft = train_model(datasetloaders, dataset_sizes, model_ft, criterion, 
                       optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)


torch.save({
            'model_state_dict': model_ft.state_dict(),
            'optimizer_state_dict': optimizer_ft.state_dict(),
            }, SAVING_CHECKPOINT)